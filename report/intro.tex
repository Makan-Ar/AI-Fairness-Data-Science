\section{Introduction} \label{sec:intro}
Machine learning is no longer an esoteric subject. Over the past decade, due to its ease of implementation and reliable accuracy, it has been adopted in a verity of diverse fields such as finance  \cite{huang2007credit, tsai2008using, galindo2000credit}, crime prediction \cite{brennan2009evaluating} and so on. Decision making in these areas has legal, moral and ethical implications, all of which should be considered while aiming for increasing prediction accuracy. The study of fairness considers the \textit{unjust} systematical discrimination against particular groups of people \cite{angwin2016machine, chouldechova2017fair, barocas2016big, berk2017fairness}. In this context, a non-discriminatory AI is not an AI that does not discriminate, it is an AI that does not cause unjust or unfair discrimination.

Interest in non-discriminatory AI has been increasing not only due to moral reasons, but also due to numerous anti-discriminatory laws in many countries. Discrimination is the prejudicial treatment of an individual based on membership in a legally protected group such as a race or gender \cite{calmon2017optimized}. These laws typically evaluate the fairness of a decision making process by means of two distinct notions: \textbf{disparate treatment} and \textbf{disparate impact} \cite{zafar2017fairness}. Disparate treatment occurs when protected attributes are used explicitly in making decisions, also known as direct discrimination. More pervasive nowadays is disparate impact, in which protected attributes are not used but reliance on variables correlated with them leads to significantly different outcomes for different groups. This can also be labled as indirect discrimination. Indirect discrimination may be intentional, as in the historical practice of \textit{redlining} in the U.S. in which home mortgages were denied in zip codes populated primarily by minorities. However, the doctrine of disparate impact applies regardless of actual intent \cite{calmon2017optimized}.

There is no universal definition of fairness. The purpose of fairness and what it means to be fair differs for every setting and this is what makes this problem extremely hard. As it is explained in Section \ref{sec:background} there are different measures and definitions of fairness and it is possible for an AI to be completely fair with respect to one measure and "unfair" to another. Thus, it is crucial to choose the right definition of fairness that embraces the needs of the project.

Furthermore, there exists an inevitable trade-off between fairness and accuracy in machine learning and almost all studies done in this area are attempts to achieve a reasonable balance in this trade-off. On the other hand, there is also a classical and long studied trade-off between accuracy and complexity in machine learning as well. The trade-off between the two is not always clear. Depending on the dataset it is possible for a simple machine learning algorithm to outperform a more complex one as it was shown by \citet{holte1993very}. However, most often that not, more complex algorithms tend to achieve a higher accuracy \cite{zemel2013learning}.

In this study, we aim to combine the two aforementioned trade-offs. We empirically analyze the trade-off between fairness and complexity. In other words, we are interested to observe how more complex algorithms perform with respect to different fairness measures. One challenging aspect of this problem is ranking the complexity of various machine learning algorithms. Some models are relatively transparent and some are known to be uninterpretable. However, ranking the complexity of most other models which are not on either extreme sides of this spectrum, would most likely be subjective and will not represent the ground truth. Moreover, although the accuracy of these models is not our main concern, we still need to utilize it to measure the goodness of fit. Nevertheless, with all the models that we implement, we aim to achieve a reasonable accuracy without taking many extra steps to increase the accuracy of any particular model.

With the dissemination of well-known machine learning (ML) models, it is almost guaranteed that most real-world machine learning applications will take advantage of one or more of these models. Furthermore, until different fair models become widely adopted, if ever, most machine learning applications will not be built with fairness in mind unless there is an obligation to do so. This only makes sense since given the recent development in fairness in ML, it is safe to say that it is not an easy task to tackle. Therefore, we believe it is of vital importance to analyze the fairness of currently well-known ML models without any alteration. More importantly, search for any correlations between fairness and complexity of a model and find general trends which can not only help inform the AI community to implement more fairness-aware models without making fairness the first priority and implementing a fairness-first model, but also inform future research in this subject on what makes an algorithm "unfair".