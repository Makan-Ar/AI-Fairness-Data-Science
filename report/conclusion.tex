\section{Conclusion}
We have empirically analyzed the trade-off between fairness and complexity in a binary classification setting, on the UCI Adult dataset, using well-known and widely used classification models in machine learning. We ranked the complexity of these models based on the time they took to fit the training set as well as the relative transparency of the intuition behind each model. Moreover, we introduced two measures of fairness based on two well-known definitions of fairness, demographic parity and equality of opportunity. Next, we used these two measures along with FPR and FNR to evaluate the fairness of each classification model. We observed that there does exists a weak trade-off between fairness and complexity. 

For future work, a more detailed analysis on this trade-off must be done on the subset level as well as replicating this empirical analysis on more datasets.